{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mercari price prediction\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.read_csv(\"C:/Users/rafal/Desktop/DS/Merceri price/data_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4348 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  item_condition_id  price  shipping    3    4    5    6    7  \\\n",
       "0           0                  1   16.0         1  0.0  0.0  0.0  0.0  0.0   \n",
       "1           1                  1   39.0         0  0.0  0.0  0.0  0.0  0.0   \n",
       "2           2                  1   50.0         0  0.0  0.0  0.0  0.0  1.0   \n",
       "3           3                  2   10.0         0  0.0  0.0  0.0  1.0  0.0   \n",
       "4           4                  3   12.0         1  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     8  ...  2490  2491  2492  2493  2494  2495  2496  2497  2498  2499  \n",
       "0  0.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "1  0.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "2  0.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "3  0.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "4  0.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 4348 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_final['price'].copy()\n",
    "data_final.drop(columns = 'price', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_final = pd.read_csv(\"C:/Users/rafal/Desktop/DS/Merceri price/data_final.csv\")\n",
    "data_final.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "y = data_final['price'].copy()\n",
    "data_final.drop(columns = 'price', inplace = True)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(data_final)\n",
    "del data_final\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "### Linear Regression\n",
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.889085495376626e+25"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_r2 = r2_score(y_test, y_pred)\n",
    "lin_reg_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3917821049503.744"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_for = RandomForestRegressor(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:25:22] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'xgb.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:21:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.3004323974948357\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-45f299156da0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5667988444770646"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_)/np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33195487926857026"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Nie moÅ¼na odnaleÅºÄ‡ okreÅ›lonego pliku",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f64d60114e77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(booster, fmap, num_trees, rankdir, ax, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    136\u001b[0m         out = backend.pipe(self._engine, format, data,\n\u001b[0;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                            quiet=quiet)\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m    228\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADYBJREFUeJzt3HGI33d9x/Hny8ROprWO5QRJou1YuhrKoO7oOoRZ0Y20fyT/FEmguEppwK0OZhE6HCr1rylDELJptolT0Fr9Qw+J5A9X6RAjudJZmpTALTpzROhZu/5TtGZ774/fT++4XHLf3v3uLt77+YDA7/v7fX6/e+fD3TO/fH/3+6WqkCRtf6/a6gEkSZvD4EtSEwZfkpow+JLUhMGXpCYMviQ1sWrwk3wuyXNJnrnC7Uny6SRzSZ5O8rbJjylJWq8hz/A/Dxy4yu13AfvGf44C/7T+sSRJk7Zq8KvqCeBnV1lyCPhCjZwC3pDkTZMaUJI0GTsn8Bi7gQtLjufH1/1k+cIkRxn9L4DXvva1f3TLLbdM4MtLUh9PPvnkT6tqai33nUTws8J1K35eQ1UdB44DTE9P1+zs7AS+vCT1keS/13rfSfyWzjywd8nxHuDiBB5XkjRBkwj+DPDe8W/r3AG8WFWXnc6RJG2tVU/pJPkycCewK8k88FHg1QBV9RngBHA3MAe8BLxvo4aVJK3dqsGvqiOr3F7AX01sIknShvCdtpLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDUxKPhJDiQ5l2QuycMr3P7mJI8neSrJ00nunvyokqT1WDX4SXYAx4C7gP3AkST7ly37O+CxqroNOAz846QHlSStz5Bn+LcDc1V1vqpeBh4FDi1bU8Drx5dvAC5ObkRJ0iQMCf5u4MKS4/nxdUt9DLg3yTxwAvjASg+U5GiS2SSzCwsLaxhXkrRWQ4KfFa6rZcdHgM9X1R7gbuCLSS577Ko6XlXTVTU9NTX1yqeVJK3ZkODPA3uXHO/h8lM29wOPAVTV94DXALsmMaAkaTKGBP80sC/JTUmuY/Si7MyyNT8G3gWQ5K2Mgu85G0m6hqwa/Kq6BDwInASeZfTbOGeSPJLk4HjZQ8ADSX4AfBm4r6qWn/aRJG2hnUMWVdUJRi/GLr3uI0sunwXePtnRJEmT5DttJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNDAp+kgNJziWZS/LwFda8J8nZJGeSfGmyY0qS1mvnaguS7ACOAX8GzAOnk8xU1dkla/YBfwu8vapeSPLGjRpYkrQ2Q57h3w7MVdX5qnoZeBQ4tGzNA8CxqnoBoKqem+yYkqT1GhL83cCFJcfz4+uWuhm4Ocl3k5xKcmClB0pyNMlsktmFhYW1TSxJWpMhwc8K19Wy453APuBO4AjwL0necNmdqo5X1XRVTU9NTb3SWSVJ6zAk+PPA3iXHe4CLK6z5RlX9sqp+CJxj9A+AJOkaMST4p4F9SW5Kch1wGJhZtubrwDsBkuxidIrn/CQHlSStz6rBr6pLwIPASeBZ4LGqOpPkkSQHx8tOAs8nOQs8Dnyoqp7fqKElSa9cqpafjt8c09PTNTs7uyVfW5J+UyV5sqqm13Jf32krSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSE4OCn+RAknNJ5pI8fJV19ySpJNOTG1GSNAmrBj/JDuAYcBewHziSZP8K664H/hr4/qSHlCSt35Bn+LcDc1V1vqpeBh4FDq2w7uPAJ4CfT3A+SdKEDAn+buDCkuP58XW/luQ2YG9VffNqD5TkaJLZJLMLCwuveFhJ0toNCX5WuK5+fWPyKuBTwEOrPVBVHa+q6aqanpqaGj6lJGndhgR/Hti75HgPcHHJ8fXArcB3kvwIuAOY8YVbSbq2DAn+aWBfkpuSXAccBmZ+dWNVvVhVu6rqxqq6ETgFHKyq2Q2ZWJK0JqsGv6ouAQ8CJ4Fngceq6kySR5Ic3OgBJUmTsXPIoqo6AZxYdt1HrrD2zvWPJUmaNN9pK0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqYlDwkxxIci7JXJKHV7j9g0nOJnk6ybeTvGXyo0qS1mPV4CfZARwD7gL2A0eS7F+27Clguqr+EPga8IlJDypJWp8hz/BvB+aq6nxVvQw8ChxauqCqHq+ql8aHp4A9kx1TkrReQ4K/G7iw5Hh+fN2V3A98a6UbkhxNMptkdmFhYfiUkqR1GxL8rHBdrbgwuReYBj650u1VdbyqpqtqempqaviUkqR12zlgzTywd8nxHuDi8kVJ3g18GHhHVf1iMuNJkiZlyDP808C+JDcluQ44DMwsXZDkNuCzwMGqem7yY0qS1mvV4FfVJeBB4CTwLPBYVZ1J8kiSg+NlnwReB3w1yX8mmbnCw0mStsiQUzpU1QngxLLrPrLk8rsnPJckacJ8p60kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNDAp+kgNJziWZS/LwCrf/VpKvjG//fpIbJz2oJGl9Vg1+kh3AMeAuYD9wJMn+ZcvuB16oqt8HPgX8/aQHlSStz5Bn+LcDc1V1vqpeBh4FDi1bcwj4t/HlrwHvSpLJjSlJWq+dA9bsBi4sOZ4H/vhKa6rqUpIXgd8Ffrp0UZKjwNHx4S+SPLOWobehXSzbq8bci0XuxSL3YtEfrPWOQ4K/0jP1WsMaquo4cBwgyWxVTQ/4+tuee7HIvVjkXixyLxYlmV3rfYec0pkH9i453gNcvNKaJDuBG4CfrXUoSdLkDQn+aWBfkpuSXAccBmaWrZkB/mJ8+R7g36vqsmf4kqSts+opnfE5+QeBk8AO4HNVdSbJI8BsVc0A/wp8Mckco2f2hwd87ePrmHu7cS8WuReL3ItF7sWiNe9FfCIuST34TltJasLgS1ITGx58P5Zh0YC9+GCSs0meTvLtJG/Zijk3w2p7sWTdPUkqybb9lbwhe5HkPePvjTNJvrTZM26WAT8jb07yeJKnxj8nd2/FnBstyeeSPHel9ypl5NPjfXo6ydsGPXBVbdgfRi/y/hfwe8B1wA+A/cvW/CXwmfHlw8BXNnKmrfozcC/eCfz2+PL7O+/FeN31wBPAKWB6q+fewu+LfcBTwO+Mj9+41XNv4V4cB94/vrwf+NFWz71Be/GnwNuAZ65w+93Atxi9B+oO4PtDHnejn+H7sQyLVt2Lqnq8ql4aH55i9J6H7WjI9wXAx4FPAD/fzOE22ZC9eAA4VlUvAFTVc5s842YZshcFvH58+QYuf0/QtlBVT3D19zIdAr5QI6eANyR502qPu9HBX+ljGXZfaU1VXQJ+9bEM282QvVjqfkb/gm9Hq+5FktuAvVX1zc0cbAsM+b64Gbg5yXeTnEpyYNOm21xD9uJjwL1J5oETwAc2Z7RrzivtCTDsoxXWY2Ify7ANDP57JrkXmAbesaETbZ2r7kWSVzH61NX7NmugLTTk+2Ino9M6dzL6X99/JLm1qv5ng2fbbEP24gjw+ar6hyR/wuj9P7dW1f9t/HjXlDV1c6Of4fuxDIuG7AVJ3g18GDhYVb/YpNk222p7cT1wK/CdJD9idI5yZpu+cDv0Z+QbVfXLqvohcI7RPwDbzZC9uB94DKCqvge8htEHq3UzqCfLbXTw/ViGRavuxfg0xmcZxX67nqeFVfaiql6sql1VdWNV3cjo9YyDVbXmD426hg35Gfk6oxf0SbKL0Sme85s65eYYshc/Bt4FkOStjIK/sKlTXhtmgPeOf1vnDuDFqvrJanfa0FM6tXEfy/AbZ+BefBJ4HfDV8evWP66qg1s29AYZuBctDNyLk8CfJzkL/C/woap6fuum3hgD9+Ih4J+T/A2jUxj3bccniEm+zOgU3q7x6xUfBV4NUFWfYfT6xd3AHPAS8L5Bj7sN90qStALfaStJTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ18f+GmWq6NWLIwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal components analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=1000, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00443277 0.00263803 0.00255027 0.0023468  0.00220149 0.00205164\n",
      " 0.00197784 0.001889   0.00179164 0.00174326 0.00168105 0.00163496\n",
      " 0.00162366 0.00159039 0.00154179 0.00151504 0.00147451 0.0014459\n",
      " 0.00143016 0.00141241 0.00136202 0.00132606 0.00131739 0.00129089\n",
      " 0.00128264 0.00126059 0.00122031 0.00121147 0.00118836 0.0011774\n",
      " 0.00115727 0.00113168 0.00112724 0.00112074 0.00109962 0.00109061\n",
      " 0.00107944 0.00107585 0.00105651 0.00104828 0.00104484 0.00103609\n",
      " 0.00102901 0.00102434 0.00101996 0.00101188 0.00100726 0.00099953\n",
      " 0.00099384 0.00098677 0.00098034 0.00098002 0.00097434 0.00096744\n",
      " 0.00096614 0.00095552 0.00094915 0.00094643 0.00094282 0.00093488\n",
      " 0.00093174 0.00092593 0.00092384 0.00092163 0.00091418 0.00090938\n",
      " 0.00090569 0.00090197 0.00089614 0.00088989 0.00088424 0.00088327\n",
      " 0.00087628 0.00086947 0.00086649 0.00086549 0.00086082 0.00085612\n",
      " 0.00085148 0.00084631 0.00084535 0.00084069 0.00083862 0.00083385\n",
      " 0.0008314  0.0008286  0.00082436 0.00082183 0.00081942 0.00081742\n",
      " 0.00081336 0.00081031 0.00080439 0.00080094 0.00080002 0.0007963\n",
      " 0.00079433 0.00079147 0.00078861 0.00078694 0.00078259 0.00078077\n",
      " 0.00078024 0.00077817 0.00077738 0.00077306 0.00077076 0.00076738\n",
      " 0.00076683 0.00076633 0.00076107 0.00075953 0.00075624 0.00075571\n",
      " 0.00075227 0.00075138 0.00074917 0.00074777 0.00074411 0.00074233\n",
      " 0.0007415  0.00073963 0.00073825 0.00073467 0.00073261 0.00073131\n",
      " 0.00073009 0.00072882 0.00072705 0.0007246  0.00072333 0.00072192\n",
      " 0.0007186  0.00071712 0.00071588 0.00071198 0.00071046 0.00070978\n",
      " 0.00070886 0.0007045  0.00070398 0.00070285 0.00070056 0.00069961\n",
      " 0.00069914 0.00069653 0.00069315 0.00069084 0.00068992 0.00068898\n",
      " 0.00068622 0.00068449 0.00068337 0.00068223 0.0006801  0.00067847\n",
      " 0.00067712 0.0006762  0.00067574 0.00067322 0.00067193 0.00067\n",
      " 0.0006685  0.00066609 0.0006635  0.00066243 0.00066077 0.00065917\n",
      " 0.00065808 0.00065731 0.00065558 0.0006537  0.00065236 0.00065028\n",
      " 0.0006471  0.0006461  0.00064562 0.00064348 0.0006421  0.00063908\n",
      " 0.00063858 0.00063793 0.00063491 0.00063414 0.00063264 0.00063144\n",
      " 0.00063076 0.00062847 0.00062694 0.00062523 0.00062439 0.00062385\n",
      " 0.0006218  0.00062152 0.00062073 0.00061887 0.00061657 0.0006151\n",
      " 0.00061497 0.00061346 0.00061336 0.00061203 0.00061047 0.0006094\n",
      " 0.00060901 0.00060652 0.00060565 0.00060493 0.00060393 0.00060288\n",
      " 0.00060178 0.00060083 0.00059855 0.0005976  0.00059734 0.0005959\n",
      " 0.00059531 0.00059331 0.00059286 0.0005921  0.00059162 0.00058964\n",
      " 0.00058909 0.00058812 0.00058739 0.0005872  0.00058601 0.00058574\n",
      " 0.0005838  0.00058311 0.00058213 0.00058008 0.00057979 0.000579\n",
      " 0.00057734 0.00057696 0.00057514 0.00057446 0.00057365 0.00057275\n",
      " 0.00057157 0.00057099 0.00057029 0.0005697  0.00056915 0.00056831\n",
      " 0.00056664 0.00056606 0.00056508 0.000565   0.00056361 0.00056316\n",
      " 0.00056232 0.00056206 0.00056095 0.0005603  0.000559   0.00055772\n",
      " 0.00055676 0.00055628 0.00055592 0.00055453 0.00055303 0.0005524\n",
      " 0.00055132 0.00055043 0.00054983 0.00054896 0.0005486  0.00054817\n",
      " 0.00054692 0.00054619 0.00054597 0.0005454  0.00054527 0.00054298\n",
      " 0.00054287 0.00054194 0.00054077 0.00053993 0.00053985 0.00053946\n",
      " 0.00053917 0.00053788 0.00053723 0.00053633 0.00053579 0.00053509\n",
      " 0.00053444 0.00053363 0.00053291 0.00053266 0.00053162 0.0005313\n",
      " 0.00053046 0.00052999 0.00052922 0.0005289  0.00052813 0.00052705\n",
      " 0.00052667 0.00052621 0.00052571 0.00052526 0.00052418 0.00052304\n",
      " 0.0005227  0.00052253 0.00052176 0.00052132 0.00052007 0.00051925\n",
      " 0.00051887 0.00051839 0.00051748 0.0005168  0.00051613 0.00051602\n",
      " 0.0005155  0.00051524 0.00051412 0.00051356 0.000513   0.00051247\n",
      " 0.00051158 0.00051059 0.00050968 0.00050943 0.00050839 0.00050822\n",
      " 0.00050785 0.00050714 0.00050681 0.0005065  0.00050545 0.00050462\n",
      " 0.00050437 0.00050351 0.00050291 0.00050216 0.0005018  0.00050081\n",
      " 0.00050049 0.00050002 0.00049943 0.00049886 0.0004984  0.00049754\n",
      " 0.00049612 0.00049598 0.00049487 0.00049453 0.00049382 0.00049321\n",
      " 0.00049299 0.00049227 0.00049141 0.00049083 0.00049023 0.00048976\n",
      " 0.00048927 0.00048889 0.00048799 0.00048761 0.00048722 0.00048677\n",
      " 0.00048578 0.00048539 0.00048494 0.00048442 0.00048364 0.00048316\n",
      " 0.00048258 0.00048186 0.00048137 0.00048101 0.00048053 0.00048028\n",
      " 0.00047967 0.00047916 0.00047828 0.00047828 0.00047781 0.00047737\n",
      " 0.00047675 0.00047646 0.00047638 0.00047505 0.00047444 0.00047402\n",
      " 0.00047371 0.00047309 0.00047232 0.00047181 0.00047151 0.00047108\n",
      " 0.00047009 0.00046979 0.00046922 0.0004688  0.00046861 0.00046729\n",
      " 0.000467   0.00046655 0.00046611 0.00046583 0.00046573 0.00046504\n",
      " 0.00046416 0.00046374 0.00046361 0.00046316 0.00046262 0.00046222\n",
      " 0.00046162 0.00046109 0.00046064 0.00046042 0.00045936 0.0004589\n",
      " 0.00045854 0.00045802 0.00045764 0.00045696 0.00045597 0.00045542\n",
      " 0.00045483 0.00045423 0.00045399 0.00045345 0.00045316 0.00045283\n",
      " 0.00045257 0.00045174 0.00045134 0.00045077 0.00045054 0.00045041\n",
      " 0.00044994 0.00044943 0.00044901 0.00044881 0.00044814 0.00044755\n",
      " 0.00044701 0.0004469  0.00044619 0.00044581 0.00044575 0.00044484\n",
      " 0.00044423 0.00044419 0.00044295 0.00044235 0.00044213 0.00044203\n",
      " 0.00044172 0.00044119 0.00044067 0.00044017 0.00043973 0.00043958\n",
      " 0.00043893 0.00043813 0.00043789 0.00043747 0.00043702 0.00043659\n",
      " 0.00043638 0.00043601 0.00043574 0.00043558 0.00043504 0.00043434\n",
      " 0.00043389 0.00043364 0.00043315 0.00043284 0.00043276 0.00043165\n",
      " 0.00043077 0.00043024 0.00043004 0.00042983 0.00042943 0.00042928\n",
      " 0.00042859 0.00042843 0.00042797 0.00042787 0.00042728 0.00042676\n",
      " 0.00042584 0.00042579 0.00042558 0.00042458 0.00042424 0.00042391\n",
      " 0.00042355 0.00042309 0.00042253 0.00042238 0.00042182 0.00042165\n",
      " 0.00042138 0.00042097 0.00042077 0.00042013 0.00041984 0.00041917\n",
      " 0.00041895 0.00041878 0.00041784 0.00041759 0.00041725 0.00041641\n",
      " 0.0004162  0.00041573 0.00041563 0.0004155  0.00041474 0.00041471\n",
      " 0.00041433 0.00041366 0.00041352 0.00041307 0.0004128  0.00041264\n",
      " 0.000412   0.00041142 0.00041133 0.00041103 0.00041085 0.00041037\n",
      " 0.00041009 0.00040963 0.00040949 0.00040907 0.00040861 0.00040788\n",
      " 0.00040768 0.00040738 0.0004072  0.00040683 0.00040639 0.00040614\n",
      " 0.0004057  0.00040528 0.00040463 0.00040422 0.00040369 0.00040323\n",
      " 0.00040278 0.00040267 0.00040243 0.00040221 0.00040186 0.00040161\n",
      " 0.00040124 0.00040085 0.00040004 0.00039957 0.00039922 0.00039904\n",
      " 0.00039883 0.00039796 0.00039745 0.00039711 0.00039698 0.00039624\n",
      " 0.00039609 0.00039604 0.00039568 0.00039536 0.000395   0.00039458\n",
      " 0.00039437 0.00039364 0.00039347 0.0003931  0.00039295 0.0003927\n",
      " 0.000392   0.00039183 0.00039147 0.00039123 0.00039086 0.00039039\n",
      " 0.00038991 0.00038961 0.00038936 0.00038887 0.00038879 0.00038841\n",
      " 0.00038781 0.00038728 0.00038693 0.00038687 0.00038639 0.00038594\n",
      " 0.00038554 0.00038544 0.00038488 0.00038455 0.00038445 0.00038432\n",
      " 0.00038386 0.00038375 0.0003834  0.00038267 0.00038256 0.00038229\n",
      " 0.00038196 0.00038156 0.00038087 0.00038071 0.00038042 0.00038025\n",
      " 0.0003797  0.00037959 0.0003795  0.00037908 0.00037854 0.00037833\n",
      " 0.00037805 0.00037772 0.00037732 0.00037701 0.00037639 0.00037625\n",
      " 0.00037604 0.00037547 0.00037517 0.00037501 0.00037451 0.00037448\n",
      " 0.00037422 0.00037404 0.00037336 0.00037313 0.00037291 0.0003727\n",
      " 0.00037235 0.00037182 0.0003715  0.0003711  0.00037088 0.00037049\n",
      " 0.00037015 0.00036975 0.00036957 0.00036927 0.0003692  0.00036867\n",
      " 0.00036829 0.0003681  0.00036757 0.00036723 0.00036705 0.00036664\n",
      " 0.00036656 0.00036606 0.00036581 0.00036535 0.00036507 0.00036486\n",
      " 0.00036431 0.0003642  0.00036367 0.00036311 0.00036276 0.00036256\n",
      " 0.00036221 0.00036198 0.00036167 0.00036159 0.00036144 0.00036063\n",
      " 0.00036034 0.00036016 0.00035996 0.00035943 0.00035936 0.00035892\n",
      " 0.0003585  0.00035832 0.0003578  0.00035759 0.00035724 0.00035694\n",
      " 0.00035661 0.00035647 0.00035617 0.00035604 0.00035551 0.00035526\n",
      " 0.00035503 0.00035469 0.00035428 0.0003542  0.00035408 0.00035335\n",
      " 0.00035303 0.00035291 0.00035252 0.00035235 0.00035178 0.00035136\n",
      " 0.00035097 0.00035069 0.00035042 0.00035036 0.00034979 0.0003496\n",
      " 0.00034952 0.00034904 0.00034883 0.00034824 0.00034805 0.0003478\n",
      " 0.00034777 0.00034737 0.0003471  0.00034692 0.00034676 0.00034647\n",
      " 0.00034617 0.00034593 0.0003453  0.00034516 0.00034483 0.00034447\n",
      " 0.00034407 0.0003438  0.00034369 0.00034317 0.00034297 0.00034252\n",
      " 0.00034243 0.00034212 0.00034179 0.00034161 0.00034119 0.00034085\n",
      " 0.00034057 0.00034028 0.00034016 0.00033993 0.00033958 0.00033939\n",
      " 0.00033915 0.00033879 0.00033875 0.00033822 0.00033811 0.00033794\n",
      " 0.00033748 0.00033709 0.00033702 0.00033678 0.00033624 0.00033584\n",
      " 0.00033574 0.0003355  0.00033514 0.00033457 0.00033418 0.00033403\n",
      " 0.000334   0.00033377 0.00033337 0.00033317 0.00033304 0.00033258\n",
      " 0.00033234 0.00033216 0.00033184 0.00033179 0.00033141 0.00033119\n",
      " 0.00033057 0.00033045 0.0003303  0.0003301  0.00032978 0.00032933\n",
      " 0.0003292  0.00032893 0.00032852 0.00032822 0.00032816 0.00032771\n",
      " 0.00032764 0.00032695 0.00032685 0.00032667 0.00032618 0.00032608\n",
      " 0.0003259  0.00032581 0.00032561 0.00032535 0.0003252  0.00032499\n",
      " 0.00032473 0.00032467 0.00032392 0.00032386 0.00032345 0.00032333\n",
      " 0.00032319 0.00032247 0.00032222 0.00032201 0.00032179 0.00032157\n",
      " 0.00032143 0.0003211  0.00032096 0.00032074 0.0003204  0.00031994\n",
      " 0.00031984 0.00031946 0.00031919 0.00031909 0.00031874 0.0003185\n",
      " 0.00031828 0.00031804 0.00031768 0.00031749 0.00031699 0.00031683\n",
      " 0.0003163  0.0003161  0.00031578 0.00031564 0.00031543 0.00031504\n",
      " 0.00031486 0.00031462 0.00031447 0.00031388 0.00031367 0.00031322\n",
      " 0.00031308 0.00031243 0.00031228 0.00031204 0.00031187 0.00031155\n",
      " 0.00031132 0.00031109 0.00031099 0.0003109  0.00031079 0.00031043\n",
      " 0.00031011 0.00030966 0.00030957 0.00030944 0.00030896 0.00030861\n",
      " 0.00030842 0.00030828 0.00030808 0.00030776 0.0003075  0.00030718\n",
      " 0.00030709 0.00030665 0.00030648 0.00030639 0.00030569 0.00030559\n",
      " 0.0003052  0.00030514 0.00030481 0.00030474 0.00030433 0.0003041\n",
      " 0.000304   0.00030373 0.00030356 0.00030318 0.00030299 0.00030287\n",
      " 0.00030238 0.00030214 0.00030194 0.00030169 0.00030118 0.00030108\n",
      " 0.0003008  0.00030049 0.00030034 0.00030015 0.00029984 0.00029949\n",
      " 0.00029929 0.00029879 0.00029855 0.00029832 0.0002979  0.00029768\n",
      " 0.00029739 0.0002971  0.00029687 0.00029657 0.00029634 0.00029608\n",
      " 0.00029588 0.00029558 0.00029508 0.00029492 0.00029474 0.00029449\n",
      " 0.00029394 0.00029377 0.00029355 0.00029332 0.00029323 0.0002929\n",
      " 0.00029253 0.00029224 0.00029214 0.00029161 0.00029127 0.00029112\n",
      " 0.00029095 0.00029081 0.00029031 0.00029013 0.00028991 0.00028986\n",
      " 0.00028954 0.00028905 0.00028878 0.00028851 0.00028806 0.00028781\n",
      " 0.00028755 0.00028736 0.00028719 0.00028699 0.00028665 0.00028618\n",
      " 0.00028598 0.00028542 0.00028507 0.00028481 0.00028473 0.00028457\n",
      " 0.00028431 0.00028385 0.00028377 0.00028326 0.00028299 0.00028283\n",
      " 0.00028235 0.00028206 0.00028161 0.0002815  0.00028106 0.00028084\n",
      " 0.00028066 0.00028047 0.00027983 0.00027979 0.00027923 0.00027879\n",
      " 0.00027837 0.00027805 0.00027779 0.00027765 0.0002775  0.00027697\n",
      " 0.00027633 0.00027624 0.00027561 0.00027543 0.00027506 0.00027455\n",
      " 0.00027412 0.00027373 0.00027357 0.00027309 0.00027283 0.00027234\n",
      " 0.00027193 0.00027151 0.00027137 0.00027107 0.00027075 0.0002701\n",
      " 0.00026969 0.00026929 0.00026902 0.00026852]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5073324098294756"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 4346)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\rafal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Building the ANN\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(units = 2200, kernel_initializer = 'uniform', activation = 'relu', input_dim = 4346))\n",
    "regressor.add(Dropout(rate = 0.1))\n",
    "regressor.add(Dense(units = 1000, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(rate = 0.1))\n",
    "regressor.add(Dense(units = 250, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(Dropout(rate = 0.1))\n",
    "regressor.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 808.8099 - mean_absolute_error: 12.8985\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 591.8345 - mean_absolute_error: 11.3914\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 436.4720 - mean_absolute_error: 10.6034\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 360.1309 - mean_absolute_error: 9.7296\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 270.2222 - mean_absolute_error: 8.7500\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 226.8965 - mean_absolute_error: 8.1511\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 215.5412 - mean_absolute_error: 7.6202\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 199.2774 - mean_absolute_error: 7.4218\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 170.2638 - mean_absolute_error: 6.9029\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 153.2279 - mean_absolute_error: 6.5164\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 143.1254 - mean_absolute_error: 6.3545\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 116.3304 - mean_absolute_error: 5.9236\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 111.7438 - mean_absolute_error: 5.6964\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 110.1365 - mean_absolute_error: 5.6365\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 128.5204 - mean_absolute_error: 5.7759\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 113.6046 - mean_absolute_error: 5.3987\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 100.9818 - mean_absolute_error: 5.3136\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 104.3540 - mean_absolute_error: 5.2093\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 100.9048 - mean_absolute_error: 5.2352\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 89.1415 - mean_absolute_error: 5.0227\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 89.6277 - mean_absolute_error: 4.8861\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 97.7213 - mean_absolute_error: 4.9987\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 89.4345 - mean_absolute_error: 4.6534\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 73.2389 - mean_absolute_error: 4.4055\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 71.0478 - mean_absolute_error: 4.2845\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 90.6817 - mean_absolute_error: 4.7487\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 92.7159 - mean_absolute_error: 4.7971\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 74.1388 - mean_absolute_error: 4.3868\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 64.7246 - mean_absolute_error: 4.3220\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 64.4918 - mean_absolute_error: 4.2822\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 87.0174 - mean_absolute_error: 4.5645\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 84.8428 - mean_absolute_error: 4.5544\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 85.1580 - mean_absolute_error: 4.4866\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 69.6775 - mean_absolute_error: 4.2000\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 64.1203 - mean_absolute_error: 4.0017\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 65.7816 - mean_absolute_error: 4.0556\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 60.5958 - mean_absolute_error: 3.8989\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 63.3667 - mean_absolute_error: 3.9570\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 52.0072 - mean_absolute_error: 3.7244\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 63.0535 - mean_absolute_error: 3.8742\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 74.5642 - mean_absolute_error: 4.1317\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 57.4727 - mean_absolute_error: 3.7660\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 108.4185 - mean_absolute_error: 4.9985\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 83.1758 - mean_absolute_error: 4.2384\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 59.3085 - mean_absolute_error: 3.8690\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 62.7495 - mean_absolute_error: 3.8458\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 67.0055 - mean_absolute_error: 3.9024\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 58.7426 - mean_absolute_error: 3.7352\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 52.4347 - mean_absolute_error: 3.6193\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 61.3086 - mean_absolute_error: 3.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24f5f9af0f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, batch_size = 256, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ann = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.97301672539711"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.2080622869687385"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2231.4517], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_pred_ann)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
